{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1616366345156,
     "user": {
      "displayName": "Abhishek Devasya Venkatramana",
      "photoUrl": "",
      "userId": "06922042641627792474"
     },
     "user_tz": 420
    },
    "id": "EW_KdqRdwAHy"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import json\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1616364820543,
     "user": {
      "displayName": "Abhishek Devasya Venkatramana",
      "photoUrl": "",
      "userId": "06922042641627792474"
     },
     "user_tz": 420
    },
    "id": "esU05LDjwTQ5",
    "outputId": "280dccbe-1f17-47e4-826d-a28e45fd2a19"
   },
   "outputs": [],
   "source": [
    "NEWS_DIRECTORY = '/media/adv/Data/PROJECTS/CSE573-SWM/News'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/adv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/adv/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/adv/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download libraries\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2yZGBQflwpNK"
   },
   "outputs": [],
   "source": [
    "def get_news_articles(path):\n",
    "    news_text = []\n",
    "    news_publish_time = []\n",
    "    news_source = []\n",
    "    \n",
    "    with os.scandir(path) as news_directories:\n",
    "        for directory in news_directories:\n",
    "            with os.scandir(os.path.join(path, directory.name)) as folder:\n",
    "                for article in folder:\n",
    "                    with open(os.path.join(path, directory.name, article.name), encoding='utf-8') as f:\n",
    "                        news_data = json.load(f)\n",
    "                    if 'site' in news_data['thread'] and news_data['thread']['site']:\n",
    "                        news_source.append(news_data['thread']['site'])\n",
    "                    else:\n",
    "                        news_source.append(None)\n",
    "                    if 'published' in news_data and news_data['published']:\n",
    "                        news_publish_time.append(news_data['published'])\n",
    "                    else:\n",
    "                        news_publish_time.append(None)\n",
    "                    if 'text' in news_data and news_data['text']:\n",
    "                        news_text.append(news_data['text'])\n",
    "                    else:\n",
    "                        news_text.append(None)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'publish_timestamp': news_publish_time,\n",
    "        'text': news_text,\n",
    "        'source': news_source,\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "news_df = get_news_articles(NEWS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-04T03:00:00.000+03:00</td>\n",
       "      <td>At its annual WWDC keynote on Monday, Apple In...</td>\n",
       "      <td>marketwatch.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-04T03:00:00.000+03:00</td>\n",
       "      <td>Amazon.com Inc.'s stock AMZN, +0.58% rallied 0...</td>\n",
       "      <td>marketwatch.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-04T15:20:00.000+03:00</td>\n",
       "      <td>New York (Reuters) - Technology stocks led the...</td>\n",
       "      <td>reuters.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-04T21:12:00.000+03:00</td>\n",
       "      <td>32d62ff48cf84493019ca98f7ced4475cef8f041\"&gt; ６月...</td>\n",
       "      <td>yahoo.co.jp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-03T23:44:00.000+03:00</td>\n",
       "      <td>Orleans Capital Management Upped Its Nextera ...</td>\n",
       "      <td>mmahotstuff.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78050</td>\n",
       "      <td>2019-02-06T16:56:00.000+02:00</td>\n",
       "      <td>-=Tableau Software (DATA) reported earnings on...</td>\n",
       "      <td>tradewitheva.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78051</td>\n",
       "      <td>2019-02-07T14:43:00.000+02:00</td>\n",
       "      <td>You follow Analyst Blog - edit You follow Zack...</td>\n",
       "      <td>zacks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78052</td>\n",
       "      <td>2019-02-07T12:32:00.000+02:00</td>\n",
       "      <td>Apple đồng ý trả hơn nửa tỷ USD tiền nợ thuế t...</td>\n",
       "      <td>vietgiaitri.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78053</td>\n",
       "      <td>2019-02-07T22:25:00.000+02:00</td>\n",
       "      <td>Apple (NASDAQ: AAPL ) has moved its modem chip...</td>\n",
       "      <td>seekingalpha.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78054</td>\n",
       "      <td>2019-02-07T10:00:00.000+02:00</td>\n",
       "      <td>Startseite » Allgemein » Technologie-Giganten ...</td>\n",
       "      <td>88finanz.de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78055 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   publish_timestamp  \\\n",
       "0      2018-06-04T03:00:00.000+03:00   \n",
       "1      2018-06-04T03:00:00.000+03:00   \n",
       "2      2018-06-04T15:20:00.000+03:00   \n",
       "3      2018-06-04T21:12:00.000+03:00   \n",
       "4      2018-06-03T23:44:00.000+03:00   \n",
       "...                              ...   \n",
       "78050  2019-02-06T16:56:00.000+02:00   \n",
       "78051  2019-02-07T14:43:00.000+02:00   \n",
       "78052  2019-02-07T12:32:00.000+02:00   \n",
       "78053  2019-02-07T22:25:00.000+02:00   \n",
       "78054  2019-02-07T10:00:00.000+02:00   \n",
       "\n",
       "                                                    text            source  \n",
       "0      At its annual WWDC keynote on Monday, Apple In...   marketwatch.com  \n",
       "1      Amazon.com Inc.'s stock AMZN, +0.58% rallied 0...   marketwatch.com  \n",
       "2      New York (Reuters) - Technology stocks led the...       reuters.com  \n",
       "3       32d62ff48cf84493019ca98f7ced4475cef8f041\"> ６月...       yahoo.co.jp  \n",
       "4       Orleans Capital Management Upped Its Nextera ...   mmahotstuff.com  \n",
       "...                                                  ...               ...  \n",
       "78050  -=Tableau Software (DATA) reported earnings on...  tradewitheva.com  \n",
       "78051  You follow Analyst Blog - edit You follow Zack...         zacks.com  \n",
       "78052  Apple đồng ý trả hơn nửa tỷ USD tiền nợ thuế t...   vietgiaitri.com  \n",
       "78053  Apple (NASDAQ: AAPL ) has moved its modem chip...  seekingalpha.com  \n",
       "78054  Startseite » Allgemein » Technologie-Giganten ...       88finanz.de  \n",
       "\n",
       "[78055 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Q6GUZqZi7M3u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publish_timestamp    0\n",
       "text                 0\n",
       "source               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timezone to UTC\n",
    "news_df['publish_timestamp'] = news_df['publish_timestamp'].apply(lambda x: datetime.fromisoformat(x).astimezone(tz=timezone.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['time'] = news_df['publish_timestamp'].apply(lambda x: x.time())\n",
    "news_df['date'] = news_df['publish_timestamp'].apply(lambda x: x.date())\n",
    "news_df['text'] = news_df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv('RawNewsData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['publish_timestamp', 'text', 'source', 'time', 'date'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['date', 'time', 'source', 'sentences']\n",
    "processed_amzn_news_df = pd.DataFrame(columns=columns)\n",
    "processed_aapl_news_df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21395 77687\n"
     ]
    }
   ],
   "source": [
    "# Extract and separate sentences containing \n",
    "for index, row in news_df.iterrows():\n",
    "    text = row['text']\n",
    "    aapl_sentences, amzn_sentences = [], []\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        if 'amazon' in sentence or 'amzn' in sentence:\n",
    "            amzn_sentences.append(sentence)\n",
    "        if 'apple' in sentence or 'aapl' in sentence:\n",
    "            aapl_sentences.append(sentence)\n",
    "    if aapl_sentences:\n",
    "        processed_aapl_news_df.loc[len(processed_aapl_news_df)] = [row['date'], row['time'], row['source'], aapl_sentences]\n",
    "    if amzn_sentences:\n",
    "        processed_amzn_news_df.loc[len(processed_amzn_news_df)] = [row['date'], row['time'], row['source'], amzn_sentences]\n",
    "        \n",
    "print(len(processed_amzn_news_df), len(processed_aapl_news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "del news_df\n",
    "processed_amzn_news_df.to_csv('AmznExtractedSentences.csv')\n",
    "processed_aapl_news_df.to_csv('AaplExtractedSentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast \n",
    "# processed_amzn_news_df1 = pd.read_csv('AmznExtractedSentences.csv', names=columns, skiprows=[0])\n",
    "# processed_amzn_news_df1['sentences'] = processed_amzn_news_df1['sentences'].apply(lambda x: ast.literal_eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>source</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>[amazon.com inc.'s stock amzn, +0.58% rallied ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>18:12:00</td>\n",
       "      <td>yahoo.co.jp</td>\n",
       "      <td>[ 32d62ff48cf84493019ca98f7ced4475cef8f041\"&gt; ６...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>15:10:00</td>\n",
       "      <td>seekingalpha.com</td>\n",
       "      <td>[aum of $66.4b\\n52-week performance vs. the s&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>[the technology sector is riding its way into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>w4t.cz</td>\n",
       "      <td>[foto: butz.2013\\njak už to v posledních letec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21390</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>15:17:00</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>[• momo crowd money flows are positive in amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21391</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>04:10:00</td>\n",
       "      <td>marketwatch.com</td>\n",
       "      <td>[that performance was good enough to land atop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21392</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>03:43:00</td>\n",
       "      <td>barrons.com</td>\n",
       "      <td>[sonos speakers also support amazon.com ’s (am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21393</td>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>14:56:00</td>\n",
       "      <td>tradewitheva.com</td>\n",
       "      <td>[posted by eva s at 5:00 pm\\nhere are some of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21394</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>88finanz.de</td>\n",
       "      <td>[unternehmen der fang-gruppe: facebook, amazon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21395 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date      time            source  \\\n",
       "0      2018-06-04  00:00:00   marketwatch.com   \n",
       "1      2018-06-04  18:12:00       yahoo.co.jp   \n",
       "2      2018-06-04  15:10:00  seekingalpha.com   \n",
       "3      2018-06-04  00:00:00   marketwatch.com   \n",
       "4      2018-06-04  00:00:00            w4t.cz   \n",
       "...           ...       ...               ...   \n",
       "21390  2019-02-07  15:17:00   marketwatch.com   \n",
       "21391  2019-02-07  04:10:00   marketwatch.com   \n",
       "21392  2019-02-07  03:43:00       barrons.com   \n",
       "21393  2019-02-06  14:56:00  tradewitheva.com   \n",
       "21394  2019-02-07  08:00:00       88finanz.de   \n",
       "\n",
       "                                               sentences  \n",
       "0      [amazon.com inc.'s stock amzn, +0.58% rallied ...  \n",
       "1      [ 32d62ff48cf84493019ca98f7ced4475cef8f041\"> ６...  \n",
       "2      [aum of $66.4b\\n52-week performance vs. the s&...  \n",
       "3      [the technology sector is riding its way into ...  \n",
       "4      [foto: butz.2013\\njak už to v posledních letec...  \n",
       "...                                                  ...  \n",
       "21390  [• momo crowd money flows are positive in amaz...  \n",
       "21391  [that performance was good enough to land atop...  \n",
       "21392  [sonos speakers also support amazon.com ’s (am...  \n",
       "21393  [posted by eva s at 5:00 pm\\nhere are some of ...  \n",
       "21394  [unternehmen der fang-gruppe: facebook, amazon...  \n",
       "\n",
       "[21395 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_amzn_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_words(input_words):\n",
    "    from nltk.corpus import words\n",
    "    \n",
    "    # Remove all non-ascii words\n",
    "    processed_words = [w for w in input_words if w.isascii()]\n",
    "    \n",
    "    # Remove punctuation words\n",
    "    tr_dict = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    processed_words = [w.translate(tr_dict) for w in processed_words if w]\n",
    "    \n",
    "    # Remove links\n",
    "    final_words = []\n",
    "    for word in processed_words:\n",
    "        if not re.match('[www]', word):\n",
    "            final_words.append(word)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_words = [w for w in final_words if w not in stop_words]\n",
    "    \n",
    "    # Stem words and return unique words\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    processed_words = list(set([stemmer.stem(word) for word in processed_words if word]))\n",
    "    \n",
    "    # Keep only words from English dictionary\n",
    "    english_words = set([w.lower() for w in words.words()])\n",
    "    processed_words = [w for w in processed_words if w in english_words]\n",
    "    \n",
    "    return processed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing 21395 records\n",
      "Completed 0 rows\n",
      "Completed 500 rows\n",
      "\n",
      "\n",
      "Processing 77687 records\n",
      "Completed 0 rows\n",
      "Completed 500 rows\n"
     ]
    }
   ],
   "source": [
    "tokenized_df_columns = ['date', 'time', 'source', 'tokens']\n",
    "tokenized_amzn_news_df = pd.DataFrame(columns=tokenized_df_columns)\n",
    "tokenized_aapl_news_df = pd.DataFrame(columns=tokenized_df_columns)\n",
    "\n",
    "print(\"\\n\\nProcessing %d records\" % len(processed_amzn_news_df))\n",
    "for index, row in processed_amzn_news_df.iterrows():\n",
    "    # This break is only for testing purpose\n",
    "    if index >= 1000:\n",
    "        break\n",
    "        \n",
    "    if index % 500 == 0:\n",
    "        print(\"Completed %d rows\" % index)\n",
    "    token_words = []\n",
    "    for sentence in row['sentences']:\n",
    "        token_words.extend(nltk.wordpunct_tokenize(sentence))\n",
    "    token_words = extract_words(token_words)\n",
    "    tokenized_amzn_news_df.loc[index] = [\n",
    "        processed_amzn_news_df.loc[index]['date'], \n",
    "        processed_amzn_news_df.loc[index]['time'], \n",
    "        processed_amzn_news_df.loc[index]['source'], \n",
    "        token_words\n",
    "    ]\n",
    "tokenized_amzn_news_df.to_csv('AmznExtractedTokens.csv')\n",
    "\n",
    "\n",
    "print(\"\\n\\nProcessing %d records\" % len(processed_aapl_news_df))\n",
    "for index, row in processed_aapl_news_df.iterrows():\n",
    "    # This break is only for testing purpose\n",
    "    if index >= 1000:\n",
    "        break\n",
    "    if index % 500 == 0:\n",
    "        print(\"Completed %d rows\" % index)\n",
    "    token_words = []\n",
    "    for sentence in row['sentences']:\n",
    "        token_words.extend(nltk.wordpunct_tokenize(sentence))\n",
    "    token_words = extract_words(token_words)\n",
    "    tokenized_aapl_news_df.loc[index] = [\n",
    "        processed_aapl_news_df.loc[index]['date'], \n",
    "        processed_aapl_news_df.loc[index]['time'], \n",
    "        processed_aapl_news_df.loc[index]['source'],\n",
    "        token_words\n",
    "    ]\n",
    "tokenized_aapl_news_df.to_csv('AaplExtractedTokens.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('AmznExtractedTokens.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenized_amzn_news_df, f)\n",
    "with open('AaplExtractedTokens.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenized_aapl_news_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edg',\n",
       " 'u',\n",
       " 'first',\n",
       " '2',\n",
       " 'dow',\n",
       " '8',\n",
       " 'averag',\n",
       " 'morn',\n",
       " 'close',\n",
       " 'enough',\n",
       " 'mark',\n",
       " 'amazon',\n",
       " 'monday',\n",
       " 'straight',\n",
       " 'toward',\n",
       " 'sinc',\n",
       " '01',\n",
       " 'industri',\n",
       " '26',\n",
       " 'streak',\n",
       " '6',\n",
       " '0',\n",
       " 'record',\n",
       " '7',\n",
       " 'capit',\n",
       " 'billion',\n",
       " 'base',\n",
       " 'humphrey',\n",
       " 'sixth',\n",
       " '83',\n",
       " 'increas',\n",
       " 'three',\n",
       " 'appl',\n",
       " 'run',\n",
       " 'reach',\n",
       " 'price',\n",
       " '58',\n",
       " 'e',\n",
       " 'help',\n",
       " '1',\n",
       " 'trade',\n",
       " '800',\n",
       " 'april',\n",
       " 'cap',\n",
       " 'boost',\n",
       " 'lift',\n",
       " '9',\n",
       " '485',\n",
       " 'market',\n",
       " 'target',\n",
       " 'compani',\n",
       " 'behind',\n",
       " 'million',\n",
       " '64',\n",
       " '000',\n",
       " '10',\n",
       " '3',\n",
       " '18',\n",
       " '801',\n",
       " 'quarter',\n",
       " 'giant',\n",
       " '943',\n",
       " 'jone',\n",
       " 'commerc',\n",
       " 'second',\n",
       " 'outstand',\n",
       " '34',\n",
       " 'stock',\n",
       " 'past',\n",
       " 'current',\n",
       " '23']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_amzn_news_df['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP28kHTgHIiEimh6OnqOEzf",
   "collapsed_sections": [],
   "name": "swm-news-preprocess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
